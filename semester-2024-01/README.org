Group meeting schedule, Spring 2024

Time 10-11am on Tuesday mornings in [[https://nauedu-prod.modolabs.net/campus_map/map/index?state=detail&feed=campus_buildings_2021_v5&id=d2bb1e0a-4b88-5944-9466-68744bdcd981][Building 90]] (SICCS), second
floor meeting room (223)

What to present?
1. your research.
2. somebody else's paper.
3. some useful software.

- Jan 16: Toby, Title: [[https://github.com/tdhock/mlr3resampling][mlr3resampling]]: cross-validation algorithms for
  the mlr3 framework in R. Abstract: cross-validation is an essential
  algorithm in any machine learning analysis. The mlr3 framework in R
  provides a standard interface to several common machine learning
  algorithms, including "standard" K-Fold cross-validation via
  =mlr3::ResamplingCV=. In this talk I will discuss two other kinds of
  K-fold cross-validation that I have implemented in the
  mlr3resampling R package. First, "Same versus Other"
  cross-validation can be used to determine the extent to which you
  can get accurate predictions, by training on some different data
  subset/group (person, image, geographic region, year, etc). Second,
  "Variable Size Train Set" cross-validation can be used to determine
  how many train set samples are necessary to get optimal prediction
  accuracy on the test set. [[https://github.com/tdhock/necromass/blob/main/HOCKING-slides-2024-01-12-berkeley.pdf][Slides]], [[https://cloud.r-project.org/web/packages/mlr3resampling/vignettes/ResamplingSameOtherCV.html][Vignette]]
- Jan 23:
  - Presenter: Tung L.Nguyen
  - Title: Optimizing Changepoint Detection through Deep Learning-based Penalty Tuning
  - Abstract: This study focuses on improving ChangePoint detection algorithms (OPART and LOPART), by dynamically learning the optimal penalty parameter, lambda. My approach aims to minimize predicted label errors using advanced deep learning methods. Comparative analysis against established methods like Bayesian Information Criterion (BIC) and Linear techniques reveals the superiority of my proposed approach in terms of accuracy. This research contributes to enhancing the adaptability and effectiveness of ChangePoint detection algorithms for improved anomaly detection in time-series data.
  - Link for the presentation: [[https://github.com/lamtung16/ML_ChangepointDetection/blob/main/Presentation_Ver1.pdf][Slides]]
- Jan 30: I will be presenting on the basic data manipulation using data.table as part of my research on expanding the open source ecosystem around data.table in R. link to my slides is in: [[https://github.com/DorisAmoakohene/presentation/blob/main/DT%20analysis%20-%20Doris%20Amoakohene_ml%20lab.pdf][here]]
- Feb 6: Guangting Yu (ASU, Applied Math) Title: Deep Learning methods
  for numerical solutions to differential equations. Abstract:
  Physics-Informed Neural Networks (PINNs) have achieved significant
  success as a machine learning method (using artificial neural
  networks) for numerically solving differential equations. We explore
  the low-rank features that emerge from training PINNs to solve
  ordinary differential equations (ODEs) and build low-rank
  architectures to leverage them, achieving a reduction in model
  complexity. We also use the Deep Ritz method to solve partial
  differential equations (PDEs) in variational form, including
  boundary-value problems and eigenvalue problems of Laplace
  equations. We adopt an alternative optimizer, Ensemble Kalman
  Inversion (EKI), to replace stochastic gradient descent/ADAM in
  minimizing the proposed loss functions. This optimizer will be
  consistently used to train the neural networks in the aforementioned
  examples for solving ODEs/PDEs. Additionally, we solve inverse
  problems in PDEs using the PINN setup to recover unknown parameters
  in PDEs, given partial or sparse observations of the PDE
  solution. Further applications of PINN to solve fractional
  differential equations will also be illustrated.  Link for the
  presentation: https://mathpost.asu.edu/~gyu If the audience are
  interested, I can stay after the presentation to run demo code
  (hand-dirty session)
- Feb 13 : Danny
- Feb 20
- Feb 27
- Mar 5
- Mar 12: spring break.
- Mar 19
- Mar 26
- Apr 2
- Apr 9
- Apr 16
- Apr 23
- Apr 30
- May 7
- May 14
- May 21
