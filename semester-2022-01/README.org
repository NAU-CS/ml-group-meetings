Group meeting schedule, Spring 2022

Time 1-2pm on Friday afternoons in SICCS 224, 
http://whenisgood.net/4rzrwzz/results/jydnfk7

1. your research.
2. somebody else's paper.
3. some useful software.

- Jan 14: Toby, [[https://github.com/NAU-CS/ml-group-meetings/blob/master/semester-2021-08/2021-08-15-research-projects.org][How to write and organize a research paper including reproducible code for making figures]].
- Jan 21: Cam, How to quickly generate labeled images for training maching and deep learning algorithms with Doodler; [[https://github.com/dbuscombe-usgs/dash_doodler/blob/main/README.md][Doodler Github Repo]]; [[https://doi.org/10.31223/X59K83][Earth ArXiv Preprint]]
- Jan 28: Toby, overview of peer review and writing a convincing reviewer response.
[[https://raw.githubusercontent.com/NAU-CS/ml-group-meetings/master/semester-2022-01/whiteboard-peer-review.jpg]]
- Feb 4: Anirban. Overleaf? Tricks in R? Toby's General Usage Rubrics (good coding requirements in class) for [[https://docs.google.com/document/d/1W6-HdQLgHayOFXaQtscO5J5yf05G7E6KeXyiBJFcT7A/edit?usp=sharing][Unsupervised Learning in R]] and [[https://docs.google.com/document/d/1wLejtG_CU-Gcc5LGBt8woliCd4DyDOfu0ZgCY2HYa0A/edit][Deep Learning in Python]]. See also [[https://tdhock.github.io/blog/2021/c-book/][my blog post about stringize macro in C]] and [[https://atrebas.github.io/post/2019-03-03-datatable-dplyr/][a comparison between dplyr and data.table syntax for data manipulation]].
- Feb 11: Kyle
https://www.bigocheatsheet.com/ - Helpful resource for Big-O notation
https://docs.google.com/presentation/d/1dJINrKnJI-mhl9M_EifEy9je8qwG_mIcdJMlUG4XsMA/edit?usp=sharing - Link to slides that I presented
- Feb 18: Brooke: link to slides-  https://docs.google.com/presentation/d/1ZaTn64VnrbqJK6vm4sOuBjfUmaOwmzlqVlICHbhIP4Q/edit?usp=sharing
Title: Code to Analyze the Efficiency of Current Peak Prediction Algorithms

Abstract: While machine learning algorithms are much more efficient in detecting peaks than manually doing so, one important factor to be evaluated is the uncertainty in their accuracy. Looking at this accuracy is important in determining if the algorithm is working as well as it is intended to. Analyzing the errors in the algorithm by code that prints images of these errors allows one to visually see if the errors in the algorithm are caused by the algorithm, by human error, or by a combination of the two. This allows us to determine if the algorithm is working as well as intended.
- Feb 25: Tayler: link to slides - https://docs.google.com/presentation/d/1sWGUx9Er9DWOEgK11_vPGdDJMIO3sRB6ta6LRYIQbKA/edit?usp=sharing
- Mar 4: Jacob
- Mar 11: cancelled.
- Mar 18: Spring Break!
- Mar 25: Toby: Advanced C++ coding techniques used in the binsegRcpp package. Abstract: binary segmentation is a classic algorithm for detecting changepoints in sequential data. In theory it should be extremely fast for N data and K segments, O(N K) in the worst case, and O(N log K) in the best case. In practice existing implementations such as ruptures (Python module) and changepoint (R package) are much slower, and in fact sometimes do not return a correct result. In this talk I will present the binsegRcpp package, which provides an efficient implementation of binary segmentation, and always returns correct results. I will also discuss some advanced C++ coding techniques (Standard Template Library containers, virtual classes, static variables, function pointers, templates, macros) which I used to avoid repetition, for efficiency, and for readability. Slides explaining binary segmentation: https://github.com/tdhock/cs499-599-fall-2021/raw/main/slides/07-binary-segmentation.pdf binsegRcpp source code: https://github.com/tdhock/binsegRcpp analysis figures/code: https://github.com/tdhock/binseg-model-selection
- Apr 1: Cancelled.
- Apr 8: Kyle: Receiver Operating Characteristic (ROC) curves are plots of true positive rate versus false positive rate which are used to evaluate binary classification algorithms. Because the Area Under the Curve (AUC) is a non-convex function of the predicted values, learning algorithms instead optimize convex relaxations which involve a sum over all pairs of labeled positive and negative examples. Naive learning algorithms compute the gradient in quadratic time, which is too slow for learning using large batch sizes. We propose a new functional representation of the square loss and squared hinge loss, which results in algorithms that compute the gradient in either linear or log-linear time, thereby making it possible for the first time to use AUC optimization with large batch sizes. In our empirical study of supervised binary classification problems, we show that our new algorithm learns much faster than the current state of the art in terms of both epochs and wall time.
Slides Link: https://github.com/rustky/sub-quadratic-full-gradient-AUC-optimization/blob/monsoon/Sub-Quadratic-AUC_slides.pdf 

-Apr 15: Brooke : Poster presentation: 
https://nau0-my.sharepoint.com/:p:/g/personal/bas664_nau_edu/EaSbwv_TDURNm9ZZlGpGjLUBE6h_DvzmVmQhNRVd34xr7g?e=5XOP5G
Abstract:
		Since sequencing the entire reference human genome, science has evolved capabilities to further our genomic research. Machine learning algorithms are an example of a tool that can be utilized to analyze immense and complex genomic data. My research utilizes machine learning algorithms to analyze samples of various tissues to determine the number of matches of DNA-binding proteins from that sample. The machine learning algorithm predicts where these matches, or peaks, are and compares them to labels of peaks created by human experts. My research focuses on evaluating the success of a machine learning algorithm known as PeakError that was previously created and analyzing the accuracy of these predictions. Such analysis allows one to inspect errors whether the algorithm incorrectly predicted a DNA match, or whether it was human error. Knowing where these DNA-proteins bind and reducing overall errors allows for examination of where possible sources of disease could arise from, and thus furthers our understanding of epigenetics.

- Apr 22: Jacob
