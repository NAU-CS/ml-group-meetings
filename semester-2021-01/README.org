Group meeting schedule, Spring 2021

Mondays 3:30-4:30 on zoom.

1. your research.
2. somebody else's paper.
3. some useful software.

- Jan 11: Toby, [[file:2021-01-11-research-projects.org][How I organize my research projects]].
- Jan 18: Holiday (no meeting).
- Jan 25: Tristan, PeakLearner [[https://docs.google.com/presentation/d/1p8_S8xGNJtD8bnYyyrEFbf0eL_6CLwdZecratmW7a70/edit#slide=id.gb8cd3eda24_0_6][Slides]], [[https://github.com/PeakLearner/PeakLearner][Code]]
- Feb 1: Jon
- Feb 8: [[https://dvvenuto.github.io/][David Venuto]], Thinking Realistically with Deep Reinforcement
  Learning.
  - Abstract: Reinforcement learning (RL) gives us a framework for
    learning how to take intelligent actions in an environment
    represented as a Markov Decision Process. Recent advances have
    been able to learn in highly complex environments by learning
    policies and value functions approximated with deep neural
    networks.  These advances come with a wide set of challenges
    including learning generalizable policies and designing good
    reward functions.  We will first give a brief introduction to the
    paradigm of RL and how we have leveraged deep learning to improve
    policy optimization.  Next, we will discuss common issues in deep
    RL and how we can learn with more robustness by leveraging expert
    data and learning modular and hierarchical policies.
- Feb 15: Alyssa: [[https://www.overleaf.com/read/zwvvfxmxrvsd][FLOPART slides]]
- Feb 22: Akhila, RcppDeepState [[https://docs.google.com/presentation/d/14qioA8F1tjMN2LJDLxR1ZzeCZrPFeCSVsMOKGcRxBlQ/edit#slide=id.p][ Slides]], [[https://github.com/akhikolla/RcppDeepState][Code]], [[https://akhikolla.github.io./][Blog]]
- Mar 1: [[https://vincentrunge.github.io/][Vincent Runge]], [[https://arxiv.org/abs/2002.03646][gfpop: an R Package for multiple change-point
  detection constrained by a graph]].
  - Abstract: The accurate detection of multiple change-points in
    univariate time series is a daily task for many engineers and
    scientists. Often, practitioners can have prior knowledge about
    the type of changes they are looking for. For example in genomic
    data, biologists expect peaks: up changes followed by down
    changes. Integrating such priors is important and requires
    dedicated algorithms. We propose with the gfpop R package a
    generic algorithm able to deal with many priors constraining the
    successive segment means. This algorithm can be seen as a Hidden
    Markov Chain model with continuous state space. gfpop works for a
    user-defined graph of constraints and several loss functions:
    Gauss, Poisson, Binomial, Biweight and Huber. This presentation
    starts with a long introduction about multiple change-point
    detection by penalized dynamic programming. The gfpop penalized
    optimization problem is solved by the functional pruning optimal
    partitioning (fpop) algorithm. This dynamic programming approach
    returns the exact minimizer. The approximate binary segmentation
    method can not be used with constraints on successive segments. We
    illustrate the use of gfpop on isotonic simulations and several
    applications in biology.
- Mar 8: Tristan: PeakLearner Labeling Activity (Fail)
- Mar 15: Arnaud Liehrmann, [[https://arxiv.org/abs/2012.06848][Increased peak detection accuracy in
  over-dispersed ChIP-seq data with supervised segmentation models]].
  - Abstract: Background: Histone modification constitutes a basic
    mechanism for the genetic regulation of gene expression. In early
    2000s, a powerful technique has emerged that couples chromatin
    immunoprecipitation with high-throughput sequencing
    (ChIP-seq). This technique provides a direct survey of the DNA
    regions associated with these modifications. In order to realize
    the full potential of this technique, increasingly sophisticated
    statistical algorithms have been developed or adapted to analyze
    the massive amount of data it generates. Many of these algorithms
    were built around natural assumptions such as the Poisson
    distribution to model the noise in the count data. In this work,
    we start from these natural assumptions and show that it is
    possible to improve upon them. Results: Our comparisons on seven
    reference datasets of histone modifications (H3K36me3 \& H3K4me3)
    suggest that natural assumptions are not always realistic under
    application conditions. We show that the unconstrained multiple
    changepoint detection model with alternative noise assumptions and
    supervised learning of the penalty parameter reduces the
    over-dispersion exhibited by count data. This model detects peaks
    more accurately than algorithms that rely on natural
    assumptions. Conclusion: The segmentation model we propose can
    benefit researchers in the field of epigenetics by providing new
    high-quality peak prediction tracks for H3K36me3 and H3k4me3
    histone modifications.
- Mar 22: [[https://www.alexdrouin.com/][Alex Drouin]], [[https://arxiv.org/abs/2007.01754][Differentiable Causal Discovery from
  Interventional Data]]. 
  - Abstract: Knowledge of the causal structure that underlies a data
    generating process is essential to answering questions of causal
    nature. Such questions are abundant in fields that involve
    decision making such as econometrics, epidemiology, and social
    sciences. When causal knowledge is unavailable, one can resort to
    causal discovery algorithms, which attempt to recover causal
    relationships from data. This talk will present a new algorithm
    for this task, that combines continuous-constrained optimization
    with the flexible density estimation capabilities of normalizing
    flows. In contrast with previous work in this direction, our
    method combines observational and interventional data to improve
    identification of the causal graph. We will present empirical
    results, along with a theoretical justification of our algorithm.
  - Short bio: Alexandre Drouin is a Research Scientist at Element AI
    in Montr√©al, Canada and an Adjunct Professor of computer science
    at Laval University. He received a PhD in machine learning from
    Laval University in 2019 for his work on antibiotic resistance
    prediction in bacterial genomes. His research interests include
    causal inference, deep learning, and bioinformatics
- Mar 29: Frank
- Apr 5: Jon [[https://drive.google.com/file/d/1_8Lz6vmORPGsB27bxS37GJXe7spKFrXr/view?usp=sharing][AUM Update Presentation Slides]], Toby [[https://github.com/tdhock/functional-pruning-theory/raw/master/HOCKING-slides.pdf][Why is functional pruning so fast for optimal changepoint detection?]]
- Apr 12: Alyssa
- Apr 19: Tristan
